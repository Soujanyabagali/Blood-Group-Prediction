{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0974680e-8b09-4d63-9eae-46f5874d4e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Classes: {'A+': 0, 'A-': 1, 'AB+': 2, 'AB-': 3, 'B+': 4, 'B-': 5, 'O+': 6, 'O-': 7}\n",
      "\n",
      "Epoch 1/25\n",
      "Training...\n",
      "Train Loss: 1.9181 Acc: 0.2696\n",
      "Validating...\n",
      "Val Loss: 1.6264 Acc: 0.3850\n",
      "\n",
      "Epoch 2/25\n",
      "Training...\n",
      "Train Loss: 1.4347 Acc: 0.4490\n",
      "Validating...\n",
      "Val Loss: 1.2811 Acc: 0.5008\n",
      "\n",
      "Epoch 3/25\n",
      "Training...\n",
      "Train Loss: 1.1569 Acc: 0.5565\n",
      "Validating...\n",
      "Val Loss: 0.9697 Acc: 0.6392\n",
      "\n",
      "Epoch 4/25\n",
      "Training...\n",
      "Train Loss: 0.8174 Acc: 0.7067\n",
      "Validating...\n",
      "Val Loss: 0.6682 Acc: 0.7525\n",
      "\n",
      "Epoch 5/25\n",
      "Training...\n",
      "Train Loss: 0.5879 Acc: 0.7829\n",
      "Validating...\n",
      "Val Loss: 0.5333 Acc: 0.7967\n",
      "\n",
      "Epoch 6/25\n",
      "Training...\n",
      "Train Loss: 0.4866 Acc: 0.8179\n",
      "Validating...\n",
      "Val Loss: 0.4581 Acc: 0.8375\n",
      "\n",
      "Epoch 7/25\n",
      "Training...\n",
      "Train Loss: 0.4244 Acc: 0.8335\n",
      "Validating...\n",
      "Val Loss: 0.3862 Acc: 0.8492\n",
      "\n",
      "Epoch 8/25\n",
      "Training...\n",
      "Train Loss: 0.3870 Acc: 0.8483\n",
      "Validating...\n",
      "Val Loss: 0.4633 Acc: 0.7992\n",
      "\n",
      "Epoch 9/25\n",
      "Training...\n",
      "Train Loss: 0.3450 Acc: 0.8671\n",
      "Validating...\n",
      "Val Loss: 0.3285 Acc: 0.8650\n",
      "\n",
      "Epoch 10/25\n",
      "Training...\n",
      "Train Loss: 0.3157 Acc: 0.8735\n",
      "Validating...\n",
      "Val Loss: 0.3724 Acc: 0.8367\n",
      "\n",
      "Epoch 11/25\n",
      "Training...\n",
      "Train Loss: 0.3384 Acc: 0.8685\n",
      "Validating...\n",
      "Val Loss: 0.3270 Acc: 0.8633\n",
      "\n",
      "Epoch 12/25\n",
      "Training...\n",
      "Train Loss: 0.2863 Acc: 0.8877\n",
      "Validating...\n",
      "Val Loss: 0.2963 Acc: 0.8742\n",
      "\n",
      "Epoch 13/25\n",
      "Training...\n",
      "Train Loss: 0.2726 Acc: 0.9000\n",
      "Validating...\n",
      "Val Loss: 0.2804 Acc: 0.8817\n",
      "\n",
      "Epoch 14/25\n",
      "Training...\n",
      "Train Loss: 0.2618 Acc: 0.8973\n",
      "Validating...\n",
      "Val Loss: 0.3631 Acc: 0.8550\n",
      "\n",
      "Epoch 15/25\n",
      "Training...\n",
      "Train Loss: 0.2446 Acc: 0.9019\n",
      "Validating...\n",
      "Val Loss: 0.3022 Acc: 0.8783\n",
      "\n",
      "Epoch 16/25\n",
      "Training...\n",
      "Train Loss: 0.2416 Acc: 0.9025\n",
      "Validating...\n",
      "Val Loss: 0.2739 Acc: 0.8850\n",
      "\n",
      "Epoch 17/25\n",
      "Training...\n",
      "Train Loss: 0.2556 Acc: 0.8956\n",
      "Validating...\n",
      "Val Loss: 0.2486 Acc: 0.8975\n",
      "\n",
      "Epoch 18/25\n",
      "Training...\n",
      "Train Loss: 0.2148 Acc: 0.9179\n",
      "Validating...\n",
      "Val Loss: 0.3041 Acc: 0.8733\n",
      "\n",
      "Epoch 19/25\n",
      "Training...\n",
      "Train Loss: 0.2375 Acc: 0.9048\n",
      "Validating...\n",
      "Val Loss: 0.3180 Acc: 0.8725\n",
      "\n",
      "Epoch 20/25\n",
      "Training...\n",
      "Train Loss: 0.2275 Acc: 0.9058\n",
      "Validating...\n",
      "Val Loss: 0.2522 Acc: 0.8933\n",
      "\n",
      "Epoch 21/25\n",
      "Training...\n",
      "Train Loss: 0.2054 Acc: 0.9196\n",
      "Validating...\n",
      "Val Loss: 0.2275 Acc: 0.9008\n",
      "\n",
      "Epoch 22/25\n",
      "Training...\n",
      "Train Loss: 0.1913 Acc: 0.9260\n",
      "Validating...\n",
      "Val Loss: 0.2694 Acc: 0.8867\n",
      "\n",
      "Epoch 23/25\n",
      "Training...\n",
      "Train Loss: 0.2082 Acc: 0.9146\n",
      "Validating...\n",
      "Val Loss: 0.2542 Acc: 0.8983\n",
      "\n",
      "Epoch 24/25\n",
      "Training...\n",
      "Train Loss: 0.1749 Acc: 0.9342\n",
      "Validating...\n",
      "Val Loss: 0.2820 Acc: 0.8900\n",
      "\n",
      "Epoch 25/25\n",
      "Training...\n",
      "Train Loss: 0.1829 Acc: 0.9240\n",
      "Validating...\n",
      "Val Loss: 0.3531 Acc: 0.8775\n",
      "Model saved to c:\\Users\\Bharath R\\Downloads\\Blood-Group-Prediction-from-Fingerprints-Using-CNN-main\\Blood-Group-Prediction-from-Fingerprints-Using-CNN-main\\Code\\.ipynb_checkpoints\\fingerprint_blood_group_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "\n",
    "# Check if CUDA is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the transformation for input images\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Set the dataset directory path\n",
    "data_dir = r\"C:\\Users\\Bharath R\\Downloads\\archive\\dataset_blood_group\"\n",
    "\n",
    "# Check if dataset directory exists\n",
    "if not os.path.exists(data_dir):\n",
    "    raise FileNotFoundError(f\"Dataset directory not found: {data_dir}\")\n",
    "\n",
    "# Load dataset\n",
    "image_dataset = datasets.ImageFolder(data_dir, transform=data_transform)\n",
    "\n",
    "# Debug: Check if the dataset loaded correctly\n",
    "print(\"Classes:\", image_dataset.class_to_idx)  # Ensure 8 classes exist\n",
    "\n",
    "# Split dataset into training and validation sets (80/20 split)\n",
    "train_size = int(0.8 * len(image_dataset))\n",
    "val_size = len(image_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(image_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders (set num_workers=0 for Windows compatibility)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "dataloaders = {\"train\": train_loader, \"val\": val_loader}\n",
    "\n",
    "# Define a simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))  # Adaptive pooling for flexibility\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, len(image_dataset.classes))  # Dynamically set classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.adaptive_pool(x)  # Ensure consistent feature map size\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "            print(\"Training...\")\n",
    "        else:\n",
    "            model.eval()\n",
    "            print(\"Validating...\")\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "        print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "model_save_path = os.path.join(os.getcwd(), \"fingerprint_blood_group_model.pth\")\n",
    "torch.save(model, model_save_path) #save entire model.\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243bf452",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b9714bc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
